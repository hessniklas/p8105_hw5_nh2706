---
title: "p8105_hw5_nh2706"
author: "Niklas Hess"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
library(patchwork)
knitr::opts_chunk$set(echo = TRUE) 
knitr::opts_chunk$set(
  fig.width = 10,
  fig.asp = .6,
  out.width = "95%")
```

# Problem 1 

Solutions provided!

# Problem 2

### Import Data & Initial Description

First, U=I import the data from the data repository within this project.
```{r, message = FALSE}
raw_homicide_df = read_csv("./data/homicide-data.csv", na = c("","Unknown"))
```

The raw data has `r ncol(raw_homicide_df)` variables and `r nrow(raw_homicide_df)` observations. Key variables include `r names(raw_homicide_df[2:8])`.

### Summarize Homicides by City

As a next step, I summarize the data by `City, State`, showing the number of total homicides and unsolved homicides. The output can be seen below the code.
```{r}
homicide_df = raw_homicide_df %>%
  mutate(city_state = str_c(city, state, sep = ", "),
         solution = ifelse(disposition == "Closed by arrest", "Solved", "Unsolved")) %>%
  group_by(city_state) %>%
  summarize(n = n(),
            unsolved = sum(solution == "Unsolved"))


knitr::kable(homicide_df)

```

### Homocides in Baltimore - Detail
As a third step, I am taking a closer look at **Baltimore, MD**, conducting a `prop.test`. The result will show the estimated proportion of homicides that are unsolved and associated Confidence Interval - see tibble table below
```{r}
baltimore_homicide = homicide_df %>%
  filter(city_state == "Baltimore, MD")

  
prop.test(
  x = baltimore_homicide %>% pull(unsolved), 
  n = baltimore_homicide %>% pull(n)) %>%
  saveRDS(file = "data/baltimore_proptest.rds")


readRDS(file = "data/baltimore_proptest.rds") %>%
  broom::tidy() %>%
  select(estimate, conf.low, conf.high) %>%
  knitr::kable(digits = 3)
```

### Prop.test Function for each city

Next, I am conducting the same test as above for each of the cities within the raw_dataset. The final output shows the estimated proportion of homicides that are unsolved and associated Confidence Interval for each city.
```{r warning = FALSE}
city_result = 
  homicide_df %>% 
  mutate(
    proportions = map2(.x = unsolved, .y = n, ~prop.test(x = .x, n = .y)),
    cleaned = map(.x = proportions, ~broom::tidy(.x))) %>% 
  unnest(cleaned) %>% 
  select(city_state, estimate, conf.low, conf.high)

city_result %>%
  knitr::kable(digits = 3)
```

### Graphing Homicide Rates in each city

Finally, I am using the data created in the previous step to graph the estimated proportion of unsolved homicides and the confidence interval for each city within a plot. The cities are organized in accordance ti their proportion of unsolved homicides, and errorbars have been added.
```{r}
city_graph = city_result %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(
    title = "Estimated proportion/CI of unresolved homicides",
    x = "City_State",
    y = "Estimate") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

city_graph
```


# Problem 3

### Initial Set-up

First, I am setting key design elements and variables to start the problem
```{r}
n = 30
sd = 5
true_mean = 0:6

dataset = function(x) {
  rnorm(n, x, sd)}

output = vector("list", length = 5000)
inter = data.frame(matrix(ncol = 3, nrow = 5000))
colnames(inter) <- c('true_mean', 'sample_mean', 'p-value')
```

### Creating initial function and final list with all 5000 datasets for each true_mean

```{r}
combine_function = function(y){
  inter2 = list()
  for (i in 1:5000) {
    output[[i]] = dataset(y)
    a = broom::tidy(t.test(output[[i]]))
    inter[i,1] = y
    inter[i,2] = a[[1]]
    inter[i,3] = a[[3]]}
  inter2 = rbind(inter2, inter)}

final_list = map(true_mean, combine_function)
```

### Converting list data into a single dataframe that can be utilized for subsequent visualization
```{r}
df_final = data.frame(c(1:5000),final_list[[1]])
for (i in 2:7) {
  df = data.frame(c(1:5000),final_list[[i]])
  df_final = rbind(df_final, df)
  }

df_final = df_final %>%
  mutate(reject = ifelse(p.value < 0.05, TRUE, FALSE))

```

### Graph #1 - Showing the proportion of times the null was rejected

```{r}
reject_plot = df_final %>%
  group_by(true_mean) %>% 
  summarize(power = sum(reject)/5000) %>% 
  ggplot(aes(x = true_mean, y = power)) +
  geom_point(aes(colour = true_mean)) +
  geom_line(alpha = 0.3) +
  labs(x = "True Mean", 
       y = "Proportion of times  null was rejected") +
  scale_x_continuous(breaks = seq(0,6,by = 1)) +
  scale_y_continuous(limits = c(0,1), breaks = seq(0,1,by = 0.2))

reject_plot
```

The graph clearly shows that as effect size increases, the power also increases. This association is in accordance with basic theory.


### Graph #2 - Comparing estimated and true Means

The following two graphs compare estimated and true means. 

-   The left graph shows the average estimate of the mean on the y axis and the true mean on the x axis for all observations.
-   The right graph shows the average estimate of the mean on the y axis and the true mean on the x axis for samples for which the null was rejected.

```{r}
Comparison_plot = df_final %>%
  group_by(true_mean) %>%
  summarize(mean_sample = mean(sample_mean)) %>%
  ggplot(aes(x = true_mean, y = mean_sample)) +
  geom_point(aes(colour = true_mean)) +
  labs(title = "Total Sample",
       x = "True Mean", 
       y = "Sample Mean") +
  scale_x_continuous(limits = c(0,6), breaks = seq(0,6,1)) +
  scale_y_continuous(limits = c(-2,7), breaks = seq(-2,7,1)) +
  theme(plot.title = element_text(hjust = 0.5))

Comparison_reject = df_final %>%
  group_by(true_mean) %>%
  filter(p.value < 0.05) %>%
  summarize(mean_sample = mean(sample_mean)) %>%
  ggplot(aes(x = true_mean, y = mean_sample)) +
  geom_point(aes(colour = true_mean)) +
  labs(title = "Rejected Null Sample",
       x = "True Mean", 
       y = "Sample Mean") +
  scale_x_continuous(limits = c(0,6), breaks = seq(0,6,1)) +
  scale_y_continuous(limits = c(-2,7), breaks = seq(-2,7,1)) +
  theme(plot.title = element_text(hjust = 0.5))

Comparison_plot + Comparison_reject
```
As the effect size increases, the sample average of the mean starts to be closer to the true mean. This makes sense, as a larger effect size increases the power.

# END
